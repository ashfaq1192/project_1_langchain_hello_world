{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfzjJANuzRKPs5mRUG/juy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashfaq1192/project_1_langchain_hello_world/blob/main/langchain_hello_world.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project No.1: Langchain Hello World"
      ],
      "metadata": {
        "id": "vtoLvHlRnoIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submitted By : Muhammad Ashfaq (ID: PIAIC209123)"
      ],
      "metadata": {
        "id": "D75iCCYtoB8_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*What is Langchain*"
      ],
      "metadata": {
        "id": "1NCl949vaTJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " That is middle layer framework that connects any LLM from backend.It is a framework used to build LLM based applications with all components like database, tool calling, connectivity, memory, rag and many other you can do. Whenever you need to change any component in AI Comound system, you just change only that specific component."
      ],
      "metadata": {
        "id": "1oMuRXKwbUfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing packages:  Langchain and Google Generative AI"
      ],
      "metadata": {
        "id": "PuTjLXCjfcsg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d68Hq3BxZ33s"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain-google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will Import the SDK"
      ],
      "metadata": {
        "id": "o5o3PLc3flfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain_google_genai as genai"
      ],
      "metadata": {
        "id": "yFmBW-web2TE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Chat Generative AI Model Object"
      ],
      "metadata": {
        "id": "_0Up1-lvcbPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "SUX_POyccMC2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We Connected with AI Studio with our API"
      ],
      "metadata": {
        "id": "GBRbT8Zzf16I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "diVR6fz1cvif"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have already imported the class \"GoogleGenerativeAI\", in this class we will pass two things. Model Name and API Key. By passing these two things, now we have object of our Langchain model"
      ],
      "metadata": {
        "id": "49AXb9UVhGkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm : ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(\n",
        "    model = 'gemini-2.0-flash-exp',\n",
        "    api_key = GOOGLE_API_KEY,\n",
        "    temperature = 0.5,\n",
        "    max_tokens= 200\n",
        ")"
      ],
      "metadata": {
        "id": "hVxePdmeclC1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response1 = llm.invoke(\"Wht is the capital of Nepal?\")"
      ],
      "metadata": {
        "id": "3kEW8NRle6fE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response1.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6BB4sNofJxL",
        "outputId": "6b2410e9-0b24-47f7-98fb-f701c4450c9b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of Nepal is **Kathmandu**.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}